### Hi Folks! You happened to stop at this profile of.....

# Abhinav Reddy Pannala
#### Graduate with expertise in Machine Learning, AI, and Software Development. Proven ability to develop scalable solutions, optimize data pipelines, and build ML models, driving significant efficiency and accuracy improvements. Proficient in Python, React, Go, ML/AI frameworks, AWS and GCP.


[📖 Master of Science in Computer Science](https://www.cise.ufl.edu/academics/graduate/masters-program/)
<br>
[🎓 Bachelor of Technology in Computer Science & Engineering](https://jaipur.manipal.edu/fosta/department-of-Computer-Science-Engineering.php)
<br>
📧 E-mail : [pannalaabhinav02@gmail.com](mailto:pannalaabhinav02@gmail.com)
<br>
🔎 LinkedIn  : [https://www.linkedin.com/in/abhinav-reddy18/](https://www.linkedin.com/in/abhinav-reddy18/)

## My Works are!!!

### 📌 [Analyzers- Comparitive Study of legal Analysis using different AI Models](https://github.com/AbhinavReddy18-bytes/Analyzers-)
- **Data Collection**: Gathered penal code datasets for California and New York, performed web scraping, and created three versions (uncleaned, cleaned, combined) by manually fixing inconsistent rows and columns.
- **Preprocessing Steps**: Applied common techniques like normalization, tokenization, text cleaning, and vectorization to prepare the data for analysis.
BERT Model Testing: Experimented with a BERT model on both datasets, adding a “STATE” category for the combined dataset. Faced complications with memory usage and errors while training with torch.no_grad().
- **Training and Code Sharing**: Each model training iteration was set to 5 epochs, but iterative tuning would be costly. A code example is shared, focusing on GPT procedures rather than the full implementation.

### 📌 [Reddit-Clone-and-Client-tester-and-simulator-with-REST-API](https://github.com/AbhinavReddy18-bytes/Reddit-Clone-and-Client-tester-and-simulator-with-REST-API-Project)
- **Engine**: Successfully implemented account registration, sub-reddit creation/join/leave, text posting, nested commenting, and up/downvoting with Karma tracking.
- **Tester/Simulator**: Created a simulator that models multiple users, handles connection/disconnection intervals, follows a Zipf distribution for sub-reddit memberships, and increases posting frequency for popular sub-reddits.
- **Architecture**: Deployed separate client processes for user actions and a single engine process for handling data. Collected performance metrics to assess system load and scalability.
- **REST API**: Developed a Reddit-like REST interface for the engine, along with a simple client that demonstrates all supported functionalities.

### 📌 [Chord: P2P System and Simulation](https://github.com/AbhinavReddy18-bytes/Chord-P2P-System-and-Simulation-Distributed-Systems)
- **Node Creation**: Successfully created and managed individual nodes, each functioning as an actor within the network.  
- **Finger Table Setup**: Implemented efficient routing via finger tables, enabling quick lookups and streamlined message forwarding.  
- **Lookup Requests**: Each node performs lookups and routes messages correctly across the entire network, following the Chord protocol.  
- **Average Hops Calculation**: Computed and displayed the average number of hops needed for message delivery, confirming routing efficiency.  
- **Routing Mechanism**: Ensured accurate node responsibility and proper message forwarding in line with the Chord protocol’s requirements.  
- **Largest Network Handled**: Validated the implementation with 3,000 nodes, each handling 3,000 requests, demonstrating scalability and robustness.  

### 📌 [Actor Modelling](https://github.com/AbhinavReddy18-bytes/Distributed-Operating-Systems-Actor-Modelling)
- Distributed work units across multiple cores to boost parallel performance, experimenting with various unit sizes to balance communication overhead and execution speed.
- Measured CPU time against real time to gauge efficiency, and tuned performance by adjusting the number of workers and limiting sequence processing.
- Resolved actor model synchronization issues for smoother parallel execution, improving error handling and debugging with a focus on actor safety and reference capabilities.
- Ran extensive tests (n=1,000,000,000; k=20; workers=4) to validate system limits, noting that higher workload parameters increased execution times.

## I possess.....

- **_💻 Languages:_** Java, C#, Python, R, MySQL, GO, JavaScript, PhP, HTMl, CSS, TypeScript, JavaScript, JSON
- **_💻 Frameworks & Libraries:_** Django, Spring Boot, React.js, TensorFlow, OpenCV, Scikit-Learn, Pickle
- **_💻 Data Analysis & Visualization:_** Tableau, Power BI, Postgre SQL, Matplotlib, NumPy, Pandas, Keras, Seaborn
- **_💻 Technologies:_** Machine Learning, MongoDB, LLM, BERT, GPT-2, T5, Retrieval-Augmented Generation, Agentic AI, Spark
- **_💻 Development Tools:_** Git, Anaconda, Figma, Jupyter NoteBook, Docker, NetBeans, Visual Studio Code
- **_💻 Other Expertise:_** Agile Methodology, KPIs, CI/CD pipelines, AWS - IAM, EC2, S3, Lambda, Bedrock, SageMaker, Glue,
GCP-ML, Data Structures and Algorithms

## I worked at.....

- **💼 Cinema Verde** _, Full-Stack Software Engineer_ (February 2025 - Present)
- **💼 College of Veterinary Medicine, University of Florida** _, Software Engineer_ (August 2023 - December 2024)
